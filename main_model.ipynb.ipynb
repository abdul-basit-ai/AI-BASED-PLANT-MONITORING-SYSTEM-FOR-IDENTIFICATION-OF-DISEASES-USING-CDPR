{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7621728,"sourceType":"datasetVersion","datasetId":4439564}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ALEXNET< SQUEEZENET, densenet , espnet,  \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import MobileNetV2 #(MobileNet, MobileNetV2, VGG16, VGG19)\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Load the dataset\ndataset = tf.keras.preprocessing.image_dataset_from_directory( '/kaggle/input/mini-plant-village',shuffle=True,\n    image_size=(256, 256),\n    batch_size=32\n)\n\n# Get the class names\nclass_names = dataset.class_names","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T17:46:39.485343Z","iopub.execute_input":"2024-04-28T17:46:39.486177Z","iopub.status.idle":"2024-04-28T17:47:03.090588Z","shell.execute_reply.started":"2024-04-28T17:46:39.486133Z","shell.execute_reply":"2024-04-28T17:47:03.089570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display sample images from the dataset\nplt.figure(figsize=(10, 10))\nfor image_batch, label_batch in dataset.take(1):\n    for i in range(12):\n        ax = plt.subplot(3, 4, i + 1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[label_batch[i]])\n        plt.savefig(\"Images_MobileNet.png\")\n\n# Define the model\ninput_shape = (256, 256, 3)\nnum_classes = len(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:47:03.092829Z","iopub.execute_input":"2024-04-28T17:47:03.093218Z","iopub.status.idle":"2024-04-28T17:47:12.394818Z","shell.execute_reply.started":"2024-04-28T17:47:03.093184Z","shell.execute_reply":"2024-04-28T17:47:12.393618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = 3\nepochs = 50\n\n\ndef get_dataset_partitions_tf(dataset, train_split=0.75, val_split=0.15, test_split=0.10, shuffle=10000):\n    # Compute the size of each partition\n    dataset_size = len(dataset)\n    train_size = int(train_split * dataset_size)\n    val_size = int(val_split * dataset_size)\n    test_size = int(test_split * dataset_size)\n\n    # Create partitions\n    train_ds = dataset.take(train_size)\n    remaining_ds = dataset.skip(train_size)\n    val_ds = remaining_ds.take(val_size)\n    test_ds = remaining_ds.skip(val_size)\n\n    return train_ds, val_ds, test_ds\n\n\ntrain_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n\n# GPU ) train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntrain_ds = train_ds.cache().shuffle(1000)\nval_ds = val_ds.cache().shuffle(1000)\ntest_ds = test_ds.cache().shuffle(1000)\n\n# resize_rescale = tf.keras.Sequential([\n#     layers.experimental.preprocessing.Rescaling(1.0/255)\n# ])\n\n# data_augmentation  = tf.keras.Sequential([\n#     layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n#     layers.experimental.preprocessing.RandomRotation(0.2),\n# ])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:47:12.396119Z","iopub.execute_input":"2024-04-28T17:47:12.396414Z","iopub.status.idle":"2024-04-28T17:47:12.425714Z","shell.execute_reply.started":"2024-04-28T17:47:12.396388Z","shell.execute_reply":"2024-04-28T17:47:12.424889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the MobileNet base model without pretrained weights\nbase_model = MobileNetV2(\n    input_shape=input_shape,\n    include_top=False,\n    weights=\"imagenet\"\n)\n\n# Freeze the base model\nbase_model.trainable = False\n\n# Create the model\nmodel = Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(num_classes, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_ds,\n                    epochs=epochs,\n                    validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:47:12.426937Z","iopub.execute_input":"2024-04-28T17:47:12.427335Z","iopub.status.idle":"2024-04-28T18:07:10.802560Z","shell.execute_reply.started":"2024-04-28T17:47:12.427308Z","shell.execute_reply":"2024-04-28T18:07:10.801697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:10.805667Z","iopub.execute_input":"2024-04-28T18:07:10.806101Z","iopub.status.idle":"2024-04-28T18:07:10.810909Z","shell.execute_reply.started":"2024-04-28T18:07:10.806066Z","shell.execute_reply":"2024-04-28T18:07:10.809724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n# plt.subplot(1,2,1)\nplt.plot(range(epochs),acc, label='Training Accuracy')\nplt.plot(range(epochs),val_acc, label='Validation Accuracy')\nplt.ylim([0, 1.1])\nyticks = [i/10 for i in range(11)]\nplt.legend(loc='lower right')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.savefig(\"Accuracy_MobileNetV2.png\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:10.812150Z","iopub.execute_input":"2024-04-28T18:07:10.812409Z","iopub.status.idle":"2024-04-28T18:07:11.212856Z","shell.execute_reply.started":"2024-04-28T18:07:10.812388Z","shell.execute_reply":"2024-04-28T18:07:11.211804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n# plt.subplot(1,2,1)\nplt.plot(range(epochs),loss, label='Training Loss')\nplt.plot(range(epochs),val_loss, label='Validation Loss')\nplt.ylim([-0.5, 10])\nplt.legend(loc='upper right')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(\"Training Loss vs Validation Loss\")\nplt.savefig(\"loss_MobileNetV2.png\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:11.214272Z","iopub.execute_input":"2024-04-28T18:07:11.214975Z","iopub.status.idle":"2024-04-28T18:07:11.593334Z","shell.execute_reply.started":"2024-04-28T18:07:11.214936Z","shell.execute_reply":"2024-04-28T18:07:11.592437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model,img):\n    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n    img_array = tf.expand_dims(img_array,0)\n    \n    prediction = model.predict(img_array)\n    predicted_class =  class_names[np.argmax(prediction[0])]\n    confidence = round(100*(np.max(prediction[0])),2)\n    return predicted_class, confidence","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:11.594323Z","iopub.execute_input":"2024-04-28T18:07:11.594568Z","iopub.status.idle":"2024-04-28T18:07:11.600623Z","shell.execute_reply.started":"2024-04-28T18:07:11.594547Z","shell.execute_reply":"2024-04-28T18:07:11.599629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor images, labels in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        predicted_class, confidence = predict(model, images[i].numpy())\n        actual_class = class_names[labels[i]]\n        plt.title(f\"Actual:{actual_class},\\n Predicted: {predicted_class}.\")\n        plt.axis(\"off\")\n        plt.savefig(\"Results_MobileNetV2\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:11.601672Z","iopub.execute_input":"2024-04-28T18:07:11.602006Z","iopub.status.idle":"2024-04-28T18:07:43.466514Z","shell.execute_reply.started":"2024-04-28T18:07:11.601980Z","shell.execute_reply":"2024-04-28T18:07:43.465331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.subplot(1,2,1)\nplt.plot(range(epochs),acc, label='Training Accuracy')\nplt.plot(range(epochs),val_acc, label='Validation Accuracy')\nplt.ylim([0, 1.1])\nplt.legend(loc='lower right')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title(\"Training Accuracy vs Validation Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(range(epochs),loss, label='Training Loss')\nplt.plot(range(epochs),val_loss, label='Validation Loss')\nplt.ylim([-0.05, 10])\nplt.legend(loc='upper right')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(\"Training Loss vs Validation Loss\")\nplt.savefig(\"combined_MobileNetV2.png\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:43.467613Z","iopub.execute_input":"2024-04-28T18:07:43.467894Z","iopub.status.idle":"2024-04-28T18:07:44.051999Z","shell.execute_reply.started":"2024-04-28T18:07:43.467870Z","shell.execute_reply":"2024-04-28T18:07:44.051088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    _, test_accuracy = model.evaluate(test_ds)\n    print(f\"Test Accuracy  :{i+1} {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:44.053285Z","iopub.execute_input":"2024-04-28T18:07:44.053589Z","iopub.status.idle":"2024-04-28T18:07:46.506168Z","shell.execute_reply.started":"2024-04-28T18:07:44.053556Z","shell.execute_reply":"2024-04-28T18:07:46.505372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n# plt.subplot(1,2,1)\nplt.plot(range(epochs),acc, label='Training Accuracy')\nplt.plot(range(epochs),val_acc, label='Validation Accuracy')\nplt.ylim([0.45, 1.0])\nyticks = [i/10 for i in range(11)]\nplt.legend(loc='lower right')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.savefig(\"Accuracy_1_MobileNetV2.png\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:46.507331Z","iopub.execute_input":"2024-04-28T18:07:46.507655Z","iopub.status.idle":"2024-04-28T18:07:46.913217Z","shell.execute_reply.started":"2024-04-28T18:07:46.507628Z","shell.execute_reply":"2024-04-28T18:07:46.912230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.figure(figsize=(10, 5))\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim(0, 3)  # Limiting y-axis from 0 to 5\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.savefig(\"loss_1_MobileNetV2.png\")  # Save the figure as loss_1.png\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:46.914590Z","iopub.execute_input":"2024-04-28T18:07:46.915176Z","iopub.status.idle":"2024-04-28T18:07:47.311491Z","shell.execute_reply.started":"2024-04-28T18:07:46.915140Z","shell.execute_reply":"2024-04-28T18:07:47.310601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_ds)\n\n# Predict the classes for the test set\ny_pred = np.argmax(model.predict(test_ds), axis=1)\n\n# Get the true classes for the test set\ny_true = np.concatenate([y for x, y in test_ds], axis=0)\n\n# Print the classification report\nprint(classification_report(y_true, y_pred, target_names=class_names))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:47.315716Z","iopub.execute_input":"2024-04-28T18:07:47.316079Z","iopub.status.idle":"2024-04-28T18:07:54.487114Z","shell.execute_reply.started":"2024-04-28T18:07:47.316049Z","shell.execute_reply":"2024-04-28T18:07:54.486206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Make predictions on the test dataset\ny_pred = []\ny_true = []\n\nfor images, labels in test_ds:\n    predictions = model.predict(images)\n    predicted_classes = np.argmax(predictions, axis=1)\n    y_pred.extend(predicted_classes)\n    y_true.extend(labels.numpy())\n\n# Generate classification report\nprint(classification_report(y_true, y_pred, target_names=class_names))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:07:54.488389Z","iopub.execute_input":"2024-04-28T18:07:54.488838Z","iopub.status.idle":"2024-04-28T18:08:04.744587Z","shell.execute_reply.started":"2024-04-28T18:07:54.488803Z","shell.execute_reply":"2024-04-28T18:08:04.743752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Make predictions on the test dataset\ny_pred = []\ny_true = []\n\nfor images, labels in test_ds:\n    predictions = model.predict(images)\n    predicted_classes = np.argmax(predictions, axis=1)\n    y_pred.extend(predicted_classes)\n    y_true.extend(labels.numpy())\n\n# Generate classification report\nreport = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n\n# Extract data from the report\nreport_data = []\nreport_data.append([\"Class\", \"Precision\", \"Recall\", \"F1-score\"])\nfor class_name in class_names:\n    precision = report[class_name][\"precision\"]\n    recall = report[class_name][\"recall\"]\n    f1_score = report[class_name][\"f1-score\"]\n    report_data.append([class_name, precision, recall, f1_score])\n\n# Plot the classification report\nfig, ax = plt.subplots(figsize=(8, 6))\nax.axis('off')\nax.axis('tight')\nax.table(cellText=report_data,\n         cellLoc='left',\n         loc='center',\n         edges='closed',\n         bbox=[0, 0, 1, 1])\nplt.savefig(\"classification_report_MobileNetV2.png\", bbox_inches='tight', pad_inches=0, facecolor='white')\nplt.close()\n\n# Open the saved image and convert it to black text on white background\nimg = Image.open(\"classification_report_MobileNetV2.png\")\nimg = img.convert(\"RGB\")\nimg_array = np.array(img)\nimg_array[img_array == 255] = 0  # Convert white pixels to black\nimg_array[img_array < 255] = 255  # Convert remaining pixels to white\nimg = Image.fromarray(img_array)\n\n# Save the final image\nimg.save(\"classification_report_final_MobileNetV2.png\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:08:04.745722Z","iopub.execute_input":"2024-04-28T18:08:04.746031Z","iopub.status.idle":"2024-04-28T18:08:13.243528Z","shell.execute_reply.started":"2024-04-28T18:08:04.746006Z","shell.execute_reply":"2024-04-28T18:08:13.242745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Directory where you want to save the TFRecord files\noutput_dir = \"/kaggle/working/test_dataset_tfrecordMobileNetV2\"\n\n# Define function to serialize data and write to TFRecord file\ndef serialize_example(image, label):\n    feature = {\n        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(image).numpy()])),\n        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\n# Create TFRecord writer\ntf_record_writer = tf.io.TFRecordWriter(output_dir)\n\n# Iterate through the dataset and serialize examples\nfor images, labels in test_ds:\n    for image, label in zip(images, labels):\n        example = serialize_example(image, label)\n        tf_record_writer.write(example)\n\n# Close the TFRecord writer\ntf_record_writer.close()\n\nprint(\"TFRecord files saved successfully_MobileNetV2.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:08:13.244633Z","iopub.execute_input":"2024-04-28T18:08:13.244909Z","iopub.status.idle":"2024-04-28T18:08:21.822475Z","shell.execute_reply.started":"2024-04-28T18:08:13.244885Z","shell.execute_reply":"2024-04-28T18:08:21.821530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nloss, top1_accuracy = model.evaluate(test_ds)\nprint(\"Top-1 Accuracy:\", top1_accuracy)\n\n# Extract true labels from the test dataset\ny_true = np.concatenate([y for x, y in test_ds], axis=0)\n\n# Predict probabilities\ny_prob = model.predict(test_ds)\n\n# Calculate top-5 accuracy\ndef top_k_accuracy(y_true, y_prob, k=5):\n    top_k = tf.nn.in_top_k(y_true, y_prob, k)\n    return np.mean(top_k)\n\ntop5_accuracy = top_k_accuracy(y_true, y_prob)\nprint(\"Top-5 Accuracy:\", top5_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:08:21.823671Z","iopub.execute_input":"2024-04-28T18:08:21.823986Z","iopub.status.idle":"2024-04-28T18:08:26.140947Z","shell.execute_reply.started":"2024-04-28T18:08:21.823961Z","shell.execute_reply":"2024-04-28T18:08:26.140047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_version=1\na = model.save('MobileNetV2.h5')\n# Save the model\nmodel.save(\"my_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:08:26.142212Z","iopub.execute_input":"2024-04-28T18:08:26.142805Z","iopub.status.idle":"2024-04-28T18:08:27.308064Z","shell.execute_reply.started":"2024-04-28T18:08:26.142770Z","shell.execute_reply":"2024-04-28T18:08:27.306696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}